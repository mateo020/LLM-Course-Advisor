{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateo020/LLM-Course-Advisor/blob/main/UofTCoursesLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxcXwtBY5MnS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQOL_E5V5h0X"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLRnxU145x2s"
      },
      "outputs": [],
      "source": [
        "website = 'https://utm.calendar.utoronto.ca/course-search'\n",
        "result = requests.get(website)\n",
        "content = result.text\n",
        "\n",
        "soup = BeautifulSoup(content, 'lxml')\n",
        "# print(soup.prettify())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OMQnttAVB42L"
      },
      "outputs": [],
      "source": [
        "print(soup.prettify())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C32d5oNRbui6"
      },
      "outputs": [],
      "source": [
        "courses = soup.find_all('div', class_='views-row')\n",
        "course_data = []\n",
        "# Loop through each course block and extract the relevant data\n",
        "for course in courses:\n",
        "    # Extract course title\n",
        "    title_div = course.find('h3', class_='js-views-accordion-group-header')\n",
        "    if title_div:\n",
        "        title = title_div.get_text(strip=True)\n",
        "    else:\n",
        "        title = \"N/A\"\n",
        "\n",
        "    # Extract course description\n",
        "    description_div = course.find('div', class_='views-field-field-desc')\n",
        "    if description_div:\n",
        "        description = description_div.get_text(strip=True)\n",
        "    else:\n",
        "        description = \"N/A\"\n",
        "\n",
        "    # Extract course prerequisites\n",
        "    prereq_span = course.find('span', class_='views-field-field-prerequisite')\n",
        "    if prereq_span:\n",
        "        prerequisites = prereq_span.get_text(strip=True)\n",
        "    else:\n",
        "        prerequisites = \"None\"\n",
        "\n",
        "    # Store the extracted information in a dictionary\n",
        "    course_info = {\n",
        "        'course': title,\n",
        "        'Description': description,\n",
        "        'Prerequisites': prerequisites\n",
        "    }\n",
        "\n",
        "    # Append the course information to the list\n",
        "    course_data.append(course_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05IqXjc8cPUD",
        "outputId": "2bb50993-7bec-4536-e144-d376c41ca3c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'course': 'ANT101H5 • Introduction to Biological Anthropology and Archaeology',\n",
              " 'Description': 'Anthropology is the global and holistic study of human biology and behaviour, and includes four subfields: biological anthropology, archaeology, sociocultural anthropology and linguistic anthropology. The material covered is directed to answering the question: What makes us human? This course is a survey of biological anthropology and archaeology.',\n",
              " 'Prerequisites': 'None'}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "course_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPKVKW7RFiCj",
        "outputId": "cec600e1-e5d9-44f7-995f-210b2c315425"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No more pages to scrape.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Start scraping from the first page\n",
        "current_page = 0\n",
        "course_data = []\n",
        "\n",
        "while True:\n",
        "    # Build the URL for the current page\n",
        "    url = f\"{website}?page={current_page}\"\n",
        "\n",
        "    # Send a request to fetch the page content\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve page {current_page}. Status code: {response.status_code}\")\n",
        "        break\n",
        "\n",
        "    # Parse the page content with BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "\n",
        "    courses = soup.find_all('div', class_='views-row')\n",
        "\n",
        "    # Loop through each course block and extract the relevant data\n",
        "    for course in courses:\n",
        "        # Extract course title\n",
        "        title_div = course.find('h3', class_='js-views-accordion-group-header')\n",
        "        if title_div:\n",
        "            title = title_div.get_text(strip=True)\n",
        "        else:\n",
        "            title = \"N/A\"\n",
        "\n",
        "        # Extract course description\n",
        "        description_div = course.find('div', class_='views-field-field-desc')\n",
        "        if description_div:\n",
        "            description = description_div.get_text(strip=True)\n",
        "        else:\n",
        "            description = \"N/A\"\n",
        "\n",
        "        # Extract course prerequisites\n",
        "        prereq_span = course.find('span', class_='views-field-field-prerequisite')\n",
        "        if prereq_span:\n",
        "            prerequisites = prereq_span.get_text(strip=True)\n",
        "        else:\n",
        "            prerequisites = \"None\"\n",
        "\n",
        "        # Store the extracted information in a dictionary\n",
        "        course_info = {\n",
        "            'Course': title,\n",
        "            'Description': description,\n",
        "            'Prerequisites': prerequisites\n",
        "        }\n",
        "\n",
        "        # Append the course information to the list\n",
        "        course_data.append(course_info)\n",
        "\n",
        "    # Find the 'next' page link\n",
        "    next_page_link = soup.find('a', title=\"Go to next page\")\n",
        "\n",
        "    # If no next page is found, break the loop\n",
        "    if not next_page_link:\n",
        "        print(\"No more pages to scrape.\")\n",
        "        break\n",
        "\n",
        "\n",
        "    current_page += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhWF4F_Vfjcu",
        "outputId": "1008e023-0c53-4304-e9a7-a42e4bad77e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4878"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "len(course_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukI6kunIzbXj",
        "outputId": "85fa4ae2-fcc2-4380-b458-9edb341baa18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Course': 'ANT101H5 • Introduction to Biological Anthropology and Archaeology',\n",
              " 'Description': 'Anthropology is the global and holistic study of human biology and behaviour, and includes four subfields: biological anthropology, archaeology, sociocultural anthropology and linguistic anthropology. The material covered is directed to answering the question: What makes us human? This course is a survey of biological anthropology and archaeology.',\n",
              " 'Prerequisites': 'None'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "course_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClgwW_lngOTs"
      },
      "source": [
        "Scraping program information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hIg-nJDzvYYD"
      },
      "outputs": [],
      "source": [
        "website = 'https://utm.calendar.utoronto.ca/list-program-areas'\n",
        "result = requests.get(website)\n",
        "content = result.text\n",
        "\n",
        "soup = BeautifulSoup(content, 'lxml')\n",
        "print(soup.prettify())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "a9mQKZr9vg7_"
      },
      "outputs": [],
      "source": [
        "links = soup.find_all('td')\n",
        "links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6Wg3JE20-zS"
      },
      "outputs": [],
      "source": [
        "program_list = []\n",
        "for td in links:\n",
        "    a_tag = td.find('a')\n",
        "    if a_tag and 'href' in a_tag.attrs:\n",
        "        href = a_tag['href']\n",
        "        # Construct the full URL (if it's a relative URL)\n",
        "        full_url = requests.compat.urljoin(url, href)\n",
        "        program_list.append(full_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMIvYYz71FvR",
        "outputId": "85a895b0-f967-4927-ff6c-b9916c166cce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(program_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mteiMIXp1IVv",
        "outputId": "84c7ce93-9d09-4100-c702-364a8269e603"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://utm.calendar.utoronto.ca/section/Anthropology'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "program_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfTDRmSs1K_y"
      },
      "outputs": [],
      "source": [
        "website = 'https://utm.calendar.utoronto.ca/section/Anthropology'\n",
        "result = requests.get(website)\n",
        "content = result.text\n",
        "\n",
        "soup = BeautifulSoup(content, 'lxml')\n",
        "print(soup.prettify())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Lsd_8DjWwt4n"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "program_info = {}\n",
        "\n",
        "# Assume program_list is a list of websites/URLs to scrape\n",
        "for field in program_list:\n",
        "    website = field\n",
        "    result = requests.get(website)\n",
        "    content = result.text\n",
        "\n",
        "    soup = BeautifulSoup(content, 'lxml')\n",
        "\n",
        "    # Extract all <p> tags for additional information if needed\n",
        "    p_tags = soup.find_all('p')\n",
        "    about = []\n",
        "    for p_tag in p_tags:\n",
        "        about.append(p_tag.get_text(separator=\"\\n\"))\n",
        "\n",
        "    # Find the 'a' tag with id=\"programs\"\n",
        "    a_tag = soup.find('a', id=\"programs\")\n",
        "    if a_tag:\n",
        "        parent_div = a_tag.find_parent('div')\n",
        "\n",
        "        # Now, within this div, find all the divs with class 'views-row'\n",
        "        posts = parent_div.find_all('div', class_='views-row')\n",
        "\n",
        "        # Loop through the posts and extract the desired information\n",
        "        for p in posts:\n",
        "            info = []\n",
        "            # Extract the title (or header) for this section\n",
        "            title_tag = p.find('h3', class_='js-views-accordion-group-header')\n",
        "\n",
        "            if title_tag:\n",
        "                # Get the title text\n",
        "                title = title_tag.get_text(strip=True)\n",
        "                print(title)\n",
        "            else:\n",
        "                title = \"No Title Found\"\n",
        "\n",
        "            # Extract the content within the 'ui-accordion-content' div\n",
        "\n",
        "            content = p.find('div', class_='view-content')\n",
        "            if content:\n",
        "              text_content = content.get_text(separator=\"\\n\")\n",
        "              print(text_content)\n",
        "\n",
        "            if content:\n",
        "                # Extract all text, including strong and a tags within the content\n",
        "                text_content = content.get_text(separator=' ', strip=True)\n",
        "                info.append(text_content)\n",
        "\n",
        "            # Only add to the dictionary if title exists and there's info to add\n",
        "            if title and info:\n",
        "                program_info[title] = info\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3KLCDTL0uvL",
        "outputId": "fbed60ba-d2ff-4e36-ac70-1aa32019c31c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "program_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zt5Uc2u85QJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for key in program_info.keys():\n",
        "  print(key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARFGbzCY-QWa"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('program_info.txt', 'w') as f:\n",
        "  for key, value_list in program_info.items():\n",
        "    concatenated_string = ' '.join(value_list)\n",
        "    f.write(f\"{key}: {concatenated_string}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfaXP4DUB5I-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "new_course_data = []\n",
        "for course in course_data:\n",
        "  if course['Course'] != 'N/A':\n",
        "    new_course_data.append(course)\n",
        "\n",
        "course_data = new_course_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o9Z94w7-_YU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "with open('course_data.txt', 'w') as f:\n",
        "  for course in course_data:\n",
        "    if course['Course'] != 'N/A':\n",
        "      f.write(f\"Course: {course['Course']}\\n\")\n",
        "      f.write(f\"Description: {course['Description']}\\n\")\n",
        "      f.write(f\"Prerequisites: {course['Prerequisites']}\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9Z0c7GFSdot"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX63rh2iEB7J"
      },
      "source": [
        "**RAG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RbyJEz1Iyc_"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain_community langchain_chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-c08NnqKFPF",
        "outputId": "6bf99159-ed0d-4011-9b77-5d3f28c34071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67nntY2gUd4u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36i9YrZaTUrI"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9EMQWFLEH0p",
        "outputId": "fbba899b-eb51-4b09-9fda-374b26ee035c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.1/375.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkvnG_KoOgpB",
        "outputId": "0968c50e-3ec3-41e1-8da8-aa1e92f6184f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj_AG-gdSUTX"
      },
      "outputs": [],
      "source": [
        "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCXr-7nIQ9pP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431af16b-b257-4430-cdfc-454d7ef6b033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Alh0AISWgqz"
      },
      "outputs": [],
      "source": [
        "# Load the local text document instead of a website\n",
        "loader = TextLoader(\"course_data.txt\", encoding=\"utf8\")  # Replace with your actual file path\n",
        "course = loader.load()\n",
        "loader = TextLoader(\"program_info (2).txt\", encoding=\"utf8\")  # Replace with your actual file path\n",
        "program = loader.load()\n",
        "\n",
        "docs = course+ program\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Embed\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=OpenAIEmbeddings())\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "#### RETRIEVAL and GENERATION ####\n",
        "\n",
        "# Prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_eCNfE_XwFA"
      },
      "outputs": [],
      "source": [
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Chain\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "oM-OkChUXz-5",
        "outputId": "64caffe5-9658-45e1-8b8d-16b55facae37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First-year required courses for a Computer Science major are CSC108H5, CSC148H5, and MAT102H5. Second-year required courses include CSC207H5, CSC236H5, and one of CSC209H5, CSC258H5, or CSC263H5. Students in the CSC minor are limited to 1.5 credits of computer science courses at the 300/400 level.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "\n",
        "# Question\n",
        "rag_chain.invoke(\"What all the are required courses to complete a comptuer science major during first and second year?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp3A2N7RXTJv"
      },
      "source": [
        "MultiQueryRetriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-GIluyOd23U"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"I am interested in a carreer in data science with a what program do you suggest and what courses will i need to take?\""
      ],
      "metadata": {
        "id": "5Yy17brogOj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
        "    retriever=vectorstore.as_retriever(), llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "eWV37zYJf7HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set logging for the queries\n",
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "Vqh6lhfuzDaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_docs = retriever_from_llm.invoke(question)\n",
        "len(unique_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVMev5aEfuuj",
        "outputId": "0644b98d-928c-47cd-e600-9b9037824cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What program would you recommend for pursuing a career in data science, and what specific courses should I consider taking?', '2. Can you suggest a suitable program for someone looking to enter the field of data science, along with a list of essential courses to enroll in?', '3. Which program do you think is best suited for aspiring data scientists, and what courses are essential for building a strong foundation in this field?']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine"
      ],
      "metadata": {
        "id": "Rz0F7hNGiVWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "jIOXYvo7ioBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi Query: Different Perspectives\n",
        "template = \"\"\"You are an AI language model assistant built to act an academic advisor at the university of Toronto. Your task is to generate five\n",
        "    different versions of the given user question to retrieve relevant documents from a vector\n",
        "    store. By generating multiple perspectives on the user question, your goal is to help\n",
        "    the user overcome some of the limitations of the distance-based similarity search. Think about what is important for a student at the university to know, note important course information such as pre requisite and program requirements.\n",
        "    Provide these alternative questions separated by newlines.\n",
        "    Original question: {question}\"\"\"\n",
        "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "generate_queries = (\n",
        "    prompt_perspectives\n",
        "    | ChatOpenAI(temperature=0)\n",
        "    | StrOutputParser()\n",
        "    | (lambda x: x.split(\"\\n\"))\n",
        ")\n"
      ],
      "metadata": {
        "id": "h81O0WMuiWpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.load import dumps, loads"
      ],
      "metadata": {
        "id": "LOVwWpGKjJ7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_union(documents: list[list]):\n",
        "    \"\"\" Unique union of retrieved docs \"\"\"\n",
        "    # Flatten list of lists, and convert each Document to string\n",
        "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
        "    # Get unique documents\n",
        "    unique_docs = list(set(flattened_docs))\n",
        "    # Return\n",
        "    return [loads(doc) for doc in unique_docs]\n",
        "\n",
        "# Retrieve\n",
        "\n",
        "question = \"I am interested in a carreer in data science with a what sta and mat courses would you suggest taking to build a strong background for an entry level data sceince role?\"\n",
        "\n",
        "\n",
        "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
        "# Tesing a single retriever\n",
        "# docs = retrieval_chain.invoke({\"question\":question})\n",
        "# len(docs)"
      ],
      "metadata": {
        "id": "wK7UTSaEi9SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter"
      ],
      "metadata": {
        "id": "d6dDkfw2jaAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"You are an academic advisor for undegraduate students at UofT, you should provided relevent program and course information\n",
        "to students. Course recommendations should be alligned with the students academic interests, suggesting courses across different fields of study is encouraged as long as prerequesite courses are stated. provide the same number of course suggestions, minimum four per year, for each first year, second year, third year, and fourth year. Provide an explanation why each course was recommended,\n",
        "base recomendations of course descriptions. Before providing an aswer ask yourself these questions: Am i suggesting all relevant courses? Am i taking into accounr the students current academic program or future careeer aspirations? Am I suggesting courses from a variety of diciplines not just one area of study?. Take a pause and make sure the answer to these questions is yes. Answer the following question based on this context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "final_rag_chain = (\n",
        "    {\"context\": retrieval_chain,\n",
        "     \"question\": itemgetter(\"question\")}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "final_rag_chain.invoke({\"question\":question})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "KXa2wQCtjQS2",
        "outputId": "77b5b669-49b4-47aa-dc9b-f56d7da627f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For a career in data science, it is important to have a strong background in statistics and mathematics. Here are some recommended STA (Statistics) and MAT (Mathematics) courses that would help you build a solid foundation for an entry-level data science role:\\n\\nFirst Year:\\n1. STA107H5 - An Introduction to Probability and Modelling (No prerequisites)\\n2. MAT134H5 - Calculus for Life Sciences I (Prerequisite for higher level math courses)\\n3. MAT135H5 - Calculus I (Prerequisite for higher level math courses)\\n4. MAT136H5 - Calculus I for Mathematical Sciences (Prerequisite for higher level math courses)\\n\\nSecond Year:\\n1. STA256H5 - Probability and Statistics I (Prerequisite: MAT134H5 or MAT136H5 or equivalent)\\n2. STA258H5 - Statistics with Applied Probability (Prerequisite: STA256H5)\\n3. MAT232H5 - Calculus of Several Variables (Prerequisite: MAT135H5 or MAT137Y5)\\n4. MAT233H5 - Linear Algebra I (Prerequisite: MAT135H5 or MAT137Y5)\\n\\nThird Year:\\n1. STA315H5 - Advanced Statistical Learning (Prerequisite: STA314H5)\\n2. STA413H5 - Estimation and Testing (Prerequisite: STA260H5)\\n3. MAT257Y5 - Complex Variables (Prerequisite: MAT232H5)\\n4. MAT244H5 - Ordinary Differential Equations (Prerequisite: MAT232H5)\\n\\nFourth Year:\\n1. STA431H5 - Structural Equation Models (Prerequisite: STA302H5 or equivalent)\\n2. ECO227Y5 - Foundations of Econometrics (Prerequisite: ECO101H5 and ECO102H5 or equivalent)\\n3. CCT226H5 - Data Analysis I (Prerequisite: CCT109H5 and CCT110H5)\\n4. LIN318H5 - Talking Numbers: Interpretation and Presentation of Quantitative Linguistic Data (Prerequisite: LIN256H5 or equivalent)\\n\\nThese courses cover a range of statistical and mathematical topics that are essential for a career in data science. Make sure to check the specific prerequisites and requirements for each course before enrolling. Good luck with your studies and future career in data science!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDObkthkfyyq"
      },
      "source": [
        "Prompt template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAvxBl9cjlSD"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "# Output parser will split the LLM result into a list of queries\n",
        "class LineList(BaseModel):\n",
        "    # \"lines\" is the key (attribute name) of the parsed output\n",
        "    lines: List[str] = Field(description=\"Lines of text\")\n",
        "\n",
        "\n",
        "class LineListOutputParser(PydanticOutputParser):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__(pydantic_object=LineList)\n",
        "\n",
        "    def parse(self, text: str) -> LineList:\n",
        "        lines = text.strip().split(\"\\n\")\n",
        "        return LineList(lines=lines)\n",
        "\n",
        "\n",
        "output_parser = LineListOutputParser()\n",
        "\n",
        "QUERY_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are an AI language model assistant built to act an academic advisor at the university of Toronto. Your task is to generate five\n",
        "    different versions of the given user question to retrieve relevant documents from a vector\n",
        "    store. By generating multiple perspectives on the user question, your goal is to help\n",
        "    the user overcome some of the limitations of the distance-based similarity search. Think about what is important for a student at the university to know, note important course information such as pre requisite and program requirements.\n",
        "    Provide these alternative questions separated by newlines.\n",
        "    Original question: {question}\"\"\",\n",
        ")\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Chain\n",
        "llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT, output_parser=output_parser)\n",
        "\n",
        "# Other inputs\n",
        "question = \"What are the approaches to Task Decomposition?\""
      ]
    },
    {
      "source": [
        "\n",
        "retriever_from_llm = MultiQueryRetriever.from_llm( retriever=vectorstore.as_retriever(), llm=llm, prompt=QUERY_PROMPT )"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ThBhg_ElY3a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_docs = retriever_from_llm.invoke(input=\"I am interested in pursuing a data career in computer science, what are some courses you suggest\")\n",
        "len(unique_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn_dS1AShpCx",
        "outputId": "7ca0f8c4-543c-4541-d73e-c7eddfe9f984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What courses should I take to prepare for a career in data science within the field of computer science?', '2. Can you recommend specific courses that would be beneficial for someone interested in a data-related career in computer science?', '3. Which courses at the University of Toronto would best align with my goal of pursuing a data career in computer science?', '4. What course options are available at U of T for students looking to specialize in data science within the computer science program?', '5. Could you provide me with a list of courses that would help me build a strong foundation for a data-focused career in computer science at U of T?']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAB430ZMrfZTT/rGv0s5eF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}